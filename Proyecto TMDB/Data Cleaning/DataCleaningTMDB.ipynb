{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar notebook."
      ],
      "metadata": {
        "id": "FlfWo1oDie3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVHF0O1p20aA"
      },
      "outputs": [],
      "source": [
        "#@title Instalar librerias y cargar conjunto de datos a limpiar { display-mode: \"form\" }\n",
        "!pip install langdetect\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pickle import HIGHEST_PROTOCOL\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plot\n",
        "from google.colab import drive\n",
        "import plotly.express as px\n",
        "import re\n",
        "from langdetect import detect\n",
        "from google.colab import data_table\n",
        "from IPython.display import HTML, display\n",
        "from IPython.display import clear_output \n",
        "from google.colab import output\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "print('\\nLeyendo archivo ',data_path + FILE_NAME + '.pkl')\n",
        "df_original = pd.read_pickle(data_path + FILE_NAME + '.pkl')\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC9kC6vs9wgD"
      },
      "source": [
        "# Información del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eozUr2Ads_tk"
      },
      "outputs": [],
      "source": [
        "#@title Estudiar columnas y tipos de datos. { display-mode: \"form\" }\n",
        "df_original.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opb2NYX7tZX1"
      },
      "outputs": [],
      "source": [
        "#@title Estudiar valores más repetidos y su número de apariciones. { display-mode: \"form\" }\n",
        "df_original['overview'].value_counts()[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh47W_zLE11N"
      },
      "source": [
        "# Eliminar argumentos no útiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7tTsz6C94pL"
      },
      "outputs": [],
      "source": [
        "#@title Remplazamos los elementos que solo contengan espacios vacios por NaN y borramos todos los NaN. { display-mode: \"form\" }\n",
        "delete = {'overview','original_title'} #Columnas en las que se eliminan elementos con NaN\n",
        "df_original.replace(r'^\\s*$', np.nan, regex = True,inplace=True)\n",
        "tam_ini = len(df_original)\n",
        "df_original.dropna(subset=delete,inplace=True)\n",
        "df_original.reset_index(drop=True,inplace=True)\n",
        "tam_fin = len(df_original)\n",
        "print(\"Se han borrado \", tam_ini - tam_fin, \" elementos que tienen NaN en las columnas \",delete,\" del dataframe.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Borramos los \"No overview found.\". { display-mode: \"form\" }\n",
        "tam_ini = len(df_original)\n",
        "df_original.drop(df_original[df_original.overview == \"No overview found.\"].index, inplace=True)\n",
        "df_original.reset_index(drop=True,inplace=True)\n",
        "tam_fin = len(df_original)\n",
        "print(\"Se han borrado \", tam_ini - tam_fin, \" elementos que tienen 'No overview found.' en la columna ovewview del dataframe.\\n\")"
      ],
      "metadata": {
        "id": "5HkXa5oXeLLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgjCNFbpMRzV"
      },
      "outputs": [],
      "source": [
        "#@title Estudiar longitud de los overview. { display-mode: \"form\" }\n",
        "df_original['overview'].str.split().\\\n",
        "  map(lambda x: len(x)).\\\n",
        "  hist(bins=100,figsize=(15,5),legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-H1oqNzvIqv"
      },
      "outputs": [],
      "source": [
        "#@title Borrar los elementos que tengan un argumento con un numero de palabras muy reducido. { display-mode: \"form\" }\n",
        "too_short = 3\n",
        "df_original['len_overview'] = [len(ov.split()) for ov in df_original.overview]\n",
        "tam_ini = len(df_original)\n",
        "short_mask = df_original['len_overview'] <= too_short\n",
        "df_original.drop(df_original[short_mask].index, inplace=True)\n",
        "df_original.reset_index(inplace=True, drop=True)\n",
        "df_original.drop('len_overview', inplace=True, axis=1)\n",
        "tam_fin = len(df_original)\n",
        "\n",
        "print(\"Se han borrado \", tam_ini - tam_fin, \" elementos del dataframe con longitud <= \",too_short)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11D6TDLrGxYc"
      },
      "outputs": [],
      "source": [
        "#@title Borrar sentencias que no están en inglés. (Aprox: 1h) { display-mode: \"form\" }\n",
        "%%time\n",
        "non_english_indices = list()\n",
        "diferent_languages = list()\n",
        "exc = list()\n",
        "fin = len(df_original)\n",
        "\n",
        "out = display(progress(0, len(df_original)), display_id=True)\n",
        "\n",
        "for i, ov in enumerate(df_original.overview):\n",
        "  try:\n",
        "    out.update(progress(i, fin))\n",
        "    lang=detect(ov)\n",
        "    if lang != 'en' and lang !='uk':\n",
        "      non_english_indices.append(i)\n",
        "      if not(lang in diferent_languages):\n",
        "        diferent_languages.append(lang)\n",
        "  except Exception:\n",
        "    exc.append(i)\n",
        "\n",
        "df_non_english = pd.DataFrame(df_original.loc[non_english_indices],copy=True)\n",
        "df_original.drop(non_english_indices, inplace=True)\n",
        "df_original.reset_index(inplace=True, drop=True)\n",
        "\n",
        "print(\"\\nNumber of non english overviews: \", len(non_english_indices))\n",
        "print(\"Diferent overview languages : \", len(diferent_languages))\n",
        "print(diferent_languages,'\\n\\n')\n",
        "print('Mostrando tabla con los elementos eliminados:\\n')\n",
        "data_table.DataTable(df_non_english, include_index=True, num_rows_per_page=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf6xXArS2WXZ"
      },
      "outputs": [],
      "source": [
        "#@title Guardar dataframe. { display-mode: \"form\" }\n",
        "\n",
        "FILE_NAME = \"similarity with bad overviews_31_08\" #@param {type:\"string\"}\n",
        "\n",
        "df_original.to_csv(data_path + FILE_NAME + '.csv',line_terminator='\\r\\n',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyKT_fgYeeLe"
      },
      "source": [
        "# Eliminar argumentos de peliculas similares a los no útiles ya conocidos - SMBC.\n",
        "\n",
        "Usaremos el explorador general para encontrar las películas con argumentos que no son utiles y que no aportan información sobre las peliculas (como los que estan definidos en la variable 'bad_overviews' en la siguiente celda).\n",
        "\n",
        "Así, una vez guardado el conjunto de datos procesado, se carga en el cuaderno de exploración para compararlo con con el conjunto de datos de 'bad_overviews' y generar la matriz de similitudes para saber que elementos eliminar del conjunto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViyxWwTdH2AN"
      },
      "outputs": [],
      "source": [
        "#@title Generar dataframe de ovewrviews no útiles. { display-mode: \"form\" }\n",
        "bad_overviews = [\"No overview\",\"No description\",\"No synopsis\",\"No plot\",\"NaN\",\"there is no information\",\n",
        "                \"None\",\"No available\",\"No disponible\",\"unavailable\",\"Overview Coming Soon\",\"No plot found anywhere online\",\n",
        "                \"unknown\",\"A plot is not available\",\"please add plot\",\"no summary available\",\"Not available at this time\",\n",
        "                \"What the movie has in store for you, wait and watch this space for more updates\", \"not description\",\"Plot unknown\",\"Know what this is about?\"]\n",
        "\n",
        "#Guardamos dataframe para usarlo en el cuaderno del explorador\n",
        "df_bad_overviews = pd.DataFrame()\n",
        "df_bad_overviews['Bad_overviews'] = bad_overviews\n",
        "df_bad_overviews.to_csv(data_path + \"bad_overviews_dataset.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXHSqu45Cgz4"
      },
      "outputs": [],
      "source": [
        "#@title Tras usar la comparación de dataframes en el SMBC cargamos la matriz de similitud obtenida. { display-mode: \"form\" }\n",
        "\n",
        "MATRIX_FILE_NAME = \"similarity with bad overviews_31_08.pkl\" #@param {type:\"string\"}\n",
        "MATRIX_FILE_NAME =  data_path + MATRIX_FILE_NAME\n",
        "try:\n",
        "  df_similares_bad_overviews = pd.read_pickle(MATRIX_FILE_NAME)\n",
        "except Exception as e:\n",
        "  print(\"Hay algún problema con el fichero indicado.\")\n",
        "  raise e\n",
        "else:\n",
        "  print(\"Matriz de similitud cargada correctamente.\")\n",
        "\n",
        "data_table.DataTable(df_similares_bad_overviews, include_index=True, num_rows_per_page=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t83drMbiZrl-"
      },
      "outputs": [],
      "source": [
        "#@title Borramos los overviews con alta similitud a los bad_overviews. { display-mode: \"form\" }\n",
        "#Utilizamos la información de la matriz para borrar.\n",
        "\n",
        "threshold = 0.5\n",
        "remove_overviews = list()\n",
        "i=0\n",
        "for cosenos in df_similares_bad_overviews['cosenos_compare']:\n",
        "  j=0\n",
        "  while j < len(cosenos) and (cosenos[j]>=threshold):\n",
        "    ind = df_similares_bad_overviews['index_compare'][i][j]\n",
        "    if not(ind in remove_overviews):\n",
        "      remove_overviews.append(ind)\n",
        "    j+=1\n",
        "  i+=1\n",
        "\n",
        "print(len(remove_overviews))\n",
        "\n",
        "data_table.DataTable(pd.DataFrame(df_original.loc[remove_overviews,'overview']), include_index=True, num_rows_per_page=20)\n",
        "\n",
        "df_original.drop(remove_overviews, inplace=True)\n",
        "df_original.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generar tablas necesarias para la DB."
      ],
      "metadata": {
        "id": "km9_BMsLgz83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzlGivc1tLEV"
      },
      "outputs": [],
      "source": [
        "#@title Generar tabla de géneros y actores. { display-mode: \"form\" }\n",
        "\n",
        "#Contamos el numero de generos distintos que hay\n",
        "diferent_genres = list()\n",
        "for i, genres in enumerate(df_original['genres']):\n",
        "    for genre in genres:\n",
        "      if not(genre in diferent_genres):\n",
        "        diferent_genres.append(genre)\n",
        "print(\"Numero de generos diferentes : \", len(diferent_genres))\n",
        "print(diferent_genres)\n",
        "\n",
        "#Sustituimos los string de los generos por su id\n",
        "new_column = []\n",
        "for list_genres in df_original['genres']:\n",
        "  new_column.append([diferent_genres.index(genre) for genre in list_genres])\n",
        "\n",
        "df_original['genres'] = new_column\n",
        "\n",
        "#Generamos csv para la base de datos que asocia id a genero\n",
        "df_genres = pd.DataFrame({'genre_id': range(0, len(diferent_genres)),'genre':diferent_genres})\n",
        "\n",
        "df_genres.to_csv(data_path + \"genres_ids.csv\",index=False)\n",
        "\n",
        "df_original['actors_string'] = [','.join(actors) for actors in df_original['actors']] #Concatenamos los actores en un string\n",
        "df_original['actors'] = df_original['actors'].apply(lambda x: np.nan if len(x)==0 else x) #Remplazar listas vacias por nan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generar tabla de películas-géneros. { display-mode: \"form\" }\n",
        "#creamos las cabeceras\n",
        "genresHeader = ['id_movie']\n",
        "for id_genre in df_genres['genre_id']:\n",
        "      aux = 'genre_' + str(id_genre)\n",
        "      genresHeader.append(aux)\n",
        "\n",
        "#Creamos la tabla\n",
        "moviesGenres = []\n",
        "for index, row in df_original.iterrows():\n",
        "    booleanArr = [False] * len(df_genres['genre_id'])\n",
        "\n",
        "    for genre in row['genres']:\n",
        "      booleanArr[genre] = True\n",
        "\n",
        "    resArr = [row['id']] + booleanArr\n",
        "    moviesGenres.append(resArr)\n",
        "\n",
        "df_moviesGenres = pd.DataFrame(moviesGenres, columns= genresHeader)\n",
        "df_moviesGenres.to_csv(data_path + \"movies_genres.csv\",index=False)"
      ],
      "metadata": {
        "id": "YMUd2gmoMB98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI9rlmCTjZrI"
      },
      "outputs": [],
      "source": [
        "#@title Guardar dataframe. { display-mode: \"form\" }\n",
        "\n",
        "FILE_NAME = \"Final_dataset\" #@param {type:\"string\"}\n",
        "\n",
        "df_original.to_csv(data_path + FILE_NAME + '.csv',line_terminator='\\r\\n',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar dataframe en español"
      ],
      "metadata": {
        "id": "CyGLA2TGoqy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Borrar películas que no están en español.\n",
        "delete = {'overview_es'} #Columnas en las que se eliminan elementos con NaN\n",
        "df_original.replace(r'^\\s*$', np.nan, regex = True,inplace=True)\n",
        "tam_ini = len(df_original)\n",
        "df_original.dropna(subset=delete,inplace=True)\n",
        "df_original.reset_index(drop=True,inplace=True)\n",
        "tam_fin = len(df_original)\n",
        "print(\"Se han borrado \", tam_ini - tam_fin, \" elementos que tienen NaN en las columnas \",delete,\" del dataframe.\\n\")"
      ],
      "metadata": {
        "id": "rSOl-G8oob9e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Guardar dataframe - Español.\n",
        "\n",
        "FILE_NAME = \"Final_dataset_spanish\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "df_original.to_csv(data_path + FILE_NAME + '.csv',line_terminator='\\r\\n',index=False)"
      ],
      "metadata": {
        "id": "s2i4Oivdo9dd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
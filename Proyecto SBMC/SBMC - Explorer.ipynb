{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5FIdRxgaLUH"
      },
      "source": [
        "**EXPLORACIÓN DE CONTENIDOS MULTIMEDIA BASADA EN LA SIMILITUD**     \n",
        "\n",
        "**SIMILARITY-BASED BROWSING OF MULTIMEDIA CONTENTS**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzs19-25rik-"
      },
      "source": [
        "# Primeros pasos: inicialización del entorno y carga del conjunto de datos a explorar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60gw2tGfbVuL"
      },
      "outputs": [],
      "source": [
        "#@title <font size = 5> Importar e instalar dependencias. { display-mode: \"form\" }\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install mysql\n",
        "!pip install mysql-connector\n",
        "!pip install pyyaml==5.4.1\n",
        "!pip install pymysql\n",
        "!pip install faiss-gpu\n",
        "!pip install hdbscan\n",
        "!pip install umap-learn\n",
        "\n",
        "import umap\n",
        "import hdbscan\n",
        "import textwrap\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import sys\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import mysql\n",
        "import mysql.connector\n",
        "import pymysql\n",
        "import faiss\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from IPython.display import clear_output \n",
        "from sentence_transformers import CrossEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.nn.functional import normalize\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "from psutil import virtual_memory\n",
        "from google.colab import drive\n",
        "from sentence_transformers import SentenceTransformer, util, models\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from sklearn.decomposition import PCA\n",
        "from mysql.connector import Error\n",
        "from sqlalchemy import create_engine\n",
        "from IPython.display import HTML, display\n",
        "from google.colab import data_table\n",
        "from google.colab import output\n",
        "\n",
        "print(\"\\nConectando con Google Drive...\\n\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "data_table._DEFAULT_FORMATTERS[float] = lambda x: f\"{x:.2f}\"\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYnnB8gVb2sa"
      },
      "outputs": [],
      "source": [
        "#@title <font size = 5> Comprobar la GPU y RAM disponible. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Esta celda comprueba si Google Colab le ha asignado una GPU o no y la cantidad de RAM que le ha concedido.\n",
        "\n",
        "#@markdown No es necesario disponer de una GPU, pero el uso de la misma hará que el código se ejecute mucho más rápido.\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU\\n\\n')\n",
        "else:\n",
        "  print(gpu_info, '\\n\\n')\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM.\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime.')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwQ_9UZ8ekkH"
      },
      "outputs": [],
      "source": [
        "#@title Iniciar el directorio de trabajo y cargar datos. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Para ejecutar el algoritmo conectaremos el cuaderno con Google Drive para almacenar la información.Esta celda conecta su cuenta drive con este notebook de Google Colab. Además inicializará el workspace necesario para ejecutar el código, creará 3 directorios: **similarity_matrix**, **saved_embeddings** y **saved_models** para almacenar las similitudes de los elementos, sus embeddings y los modelos que se deseen almacenar respectivamente.\n",
        "\n",
        "#@markdown Para ello se deben indicar los siguientes argumentos:\n",
        "\n",
        "#@markdown *   **WS_PATH**: Ruta del directorio de trabajo.Es la carpeta en la que se crearán los directorios anteriormente mencionados. **(Ejemplo:᠎ ᠎/content/drive/general_explorer/)**.\n",
        "\n",
        "#@markdown *   **FILE_NAME**: Nombre del conjunto de datos que deseas explorar. Debe estar en la carpeta WS_PATH y debe de ser un fichero de  formato csv. **(Ejemplo: arxiv_data.csv)**.\n",
        "\n",
        "#@markdown *   **TITLE_COLUM**: Nombre de la columna del conjunto de datos que contiene los títulos de los elementos.\n",
        "\n",
        "#@markdown *   **EMBD_COLUM**: Nombre de la columna del conjunto de datos que contiene los textos sobre los que se realizará la exploración.\n",
        "\n",
        "#@markdown *   **LOAD_FULL_CSV**: Si la casilla está marcada, se cargará el fichero indicado en FILE_NAME entero, en otro caso se deberá indicar el número de filas que desea cargar en el siguiente argumento.\n",
        "\n",
        "#@markdown *   **NUMBER_OF_ROWS**: Número de filas que serán cargadas del archivo indicado en FILE_NAME si no está marcada la anterior casilla.\n",
        "\n",
        "#@markdown  <br>\n",
        "\n",
        "WS_PATH =\"/content/drive/\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"arxiv_data.csv\" #@param {type:\"string\"}\n",
        "EMBD_COLUMN = \"abstracts\" #@param {type:\"string\"}\n",
        "TITLE_COLUMN = \"titles\" #@param {type:\"string\"}\n",
        "LOAD_FULL_CSV = True #@param {type:\"boolean\"}\n",
        "NUMBER_OF_ROWS =  100#@param {type:\"integer\"}\n",
        "\n",
        "print(\"\\nInicializando...\\n\")\n",
        "\n",
        "def ensure_mkdir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "similarity_matrix_dir = WS_PATH + \"similarity_matrix/\"\n",
        "saved_embeddings_dir = WS_PATH + \"saved_embeddings/\"\n",
        "saved_models_dir = WS_PATH + \"saved_models/\"\n",
        "\n",
        "ensure_mkdir(similarity_matrix_dir)\n",
        "ensure_mkdir(saved_embeddings_dir)\n",
        "ensure_mkdir(saved_models_dir)\n",
        "\n",
        "if LOAD_FULL_CSV:\n",
        "  df = pd.read_csv(WS_PATH + FILE_NAME)\n",
        "else:\n",
        "  df = pd.read_csv(WS_PATH + FILE_NAME,nrows=NUMBER_OF_ROWS)\n",
        "\n",
        "print(\"Columnas cargadas: \", list(df.columns))\n",
        "if EMBD_COLUMN not in df.columns:\n",
        "  raise Exception(\"La columna {} no se encuentra en el conjunto de datos cargado.\".format(EMBD_COLUMN))\n",
        "\n",
        "\n",
        "#df['id'] = range(0, len(df))\n",
        "print(\"Número de elementos cargados: \", len(df), '\\n')\n",
        "print(\"Mostrando los primeros elementos:\\n\")\n",
        "\n",
        "data_table.DataTable(df.head(), include_index=True, num_rows_per_page=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUexGZg1pIMI"
      },
      "source": [
        "# Cálculo o carga de los sentence embeddings y exploración en el espacio: Bi-Encoder.\n",
        "\n",
        "En esta sección se calculan o cargan los sentence embeddings de los textos indicados del conjunto de datos.\n",
        "\n",
        "Para crear los embeddings existe una larga lista de modelos ya entrenados que se encuentran disponibles en [HuggingFace](https://huggingface.co/), se puede observar el rendimiento de los mismos [aquí](https://www.sbert.net/_static/html/models_en_sentence_embeddings.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGEqbya3rrBo"
      },
      "outputs": [],
      "source": [
        "#@title Iniciar el modelo: { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown En esta celda se inicializa el modelo y se puede observar gráficamente la distribución de las longitudes de los textos.\n",
        "\n",
        "#@markdown Se deben indicar los siguientes parámetros:\n",
        "\n",
        "#@markdown *   **MODEL_NAME_BIENCODER**: Nombre del modelo que se va a utilizar para generar los sentence embeddings. Se puede seleccionar cualquiera de la lista desplegable o de la web HugginFace. Si el modelo esta en la carpeta de saved_models se cargará de esa carpeta.\n",
        "\n",
        "#@markdown *   **SAVE_MODEL**: Si esta marcado se guarda el modelo en la carpeta de saved_models. Así, al cargar el modelo, primero mira si esta guardado para cargarlo de esta carpeta.\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "MODEL_NAME_BIENCODER = \"sentence-transformers/all-MiniLM-L6-v2\" #@param [\"sentence-transformers/paraphrase-MiniLM-L6-v2\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", \"sentence-transformers/LaBSE\", \"sentence-transformers/all-mpnet-base-v2\", \"sentence-transformers/all-distilroberta-v1\", \"sentence-transformers/multi-qa-mpnet-base-dot-v1\", \"sentence-transformers/all-MiniLM-L6-v2\", \"stsb-roberta-large\"] {allow-input: true}\n",
        "SAVE_MODEL = False #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"Initializing the model...\\n\")\n",
        "if os.path.exists(WS_PATH + \"saved_models/\" + MODEL_NAME_BIENCODER):\n",
        "  BIENCODER_MODEL = SentenceTransformer(model_name_or_path = WS_PATH + \"saved_models/\" + MODEL_NAME_BIENCODER)\n",
        "else:\n",
        "  BIENCODER_MODEL = SentenceTransformer(model_name_or_path = MODEL_NAME_BIENCODER)\n",
        "\n",
        "print('Modelo descargado:\\n')\n",
        "print(BIENCODER_MODEL,'\\n')\n",
        "\n",
        "df[EMBD_COLUMN] = df[EMBD_COLUMN].astype(\"string\")\n",
        "try:\n",
        "  df[EMBD_COLUMN].str.split().\\\n",
        "    map(lambda x: len(x)).plot.hist(bins=200,alpha = 0.7,figsize=(15,5),title = 'Frecuencia del número de palabras por sentencia.',legend=True)\n",
        "except:\n",
        "  print(\"No se puede dibujar la gráfica porque no todos los elementos son strings.\")\n",
        "\n",
        "#Movemos modelo a GPU\n",
        "print('Moving model to', device, \".\")\n",
        "BIENCODER_MODEL = BIENCODER_MODEL.to(device)\n",
        "\n",
        "if SAVE_MODEL:\n",
        "  BIENCODER_MODEL.save(WS_PATH + \"saved_models/\" + MODEL_NAME_BIENCODER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vih6NRYGuOsM"
      },
      "outputs": [],
      "source": [
        "#@title Calcular los sentence embeddings. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown En la celda actual se deben indicar los siguientes parámetros:\n",
        "\n",
        "#@markdown *   **MAX_SEQ_LEN** : Maxima longitud de los textos a procesar.Textos con un número mayor de palabras serán truncados. Si es -1 se usará el valor por defecto del modelo seleccionado. Puedes ayudarte de la gráfica anteriormente generada para ajustar este valor. **(Ejemplo: 512)**.\n",
        "\n",
        "#@markdown *   **NORMALIZE_EMBEDDINGS** :  Si está marcada los embeddings serán normalizados. Recomendable si se quiere obtener similitudes entre 0 y 1.\n",
        "\n",
        "#@markdown *   **SAVE_EMBEDDINGS** : Si está marcada los embeddings serán guardados con el nombre indicado en el parametro OUTPUT_NAME_EMBEDDINGS.\n",
        "\n",
        "#@markdown *   **OUTPUT_NAME_EMBEDDINGS** : Nombre con el que serán guardados los embeddings. **(Ejemplo: embeddings-peliculas)**\n",
        "\n",
        "BIENCODER_BATCH_SIZE = 32\n",
        "MAX_SEQ_LEN =  -1#@param {type:\"integer\"}\n",
        "NORMALIZE_EMBEDDINGS = True #@param {type:\"boolean\"}\n",
        "SAVE_EMBEDDINGS = True #@param {type:\"boolean\"}\n",
        "\n",
        "OUTPUT_NAME_EMBEDDINGS = \"embeddings-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "if MAX_SEQ_LEN != -1:\n",
        "  BIENCODER_MODEL._first_module().max_seq_length  = MAX_SEQ_LEN\n",
        "\n",
        "print('Usando el modelo:\\n')\n",
        "print(BIENCODER_MODEL)\n",
        "\n",
        "print('\\nComputing embeddings...')\n",
        "sentences = [str(x) for x in df[EMBD_COLUMN].tolist()]\n",
        "embeddings = BIENCODER_MODEL.encode(sentences,\n",
        "                                    convert_to_tensor=False,\n",
        "                                    device = str(device),\n",
        "                                    batch_size = BIENCODER_BATCH_SIZE,\n",
        "                                    show_progress_bar=True,\n",
        "                                    normalize_embeddings= NORMALIZE_EMBEDDINGS)\n",
        "\n",
        "def is_normalized(sentence_embeddigs):\n",
        "  for e in sentence_embeddigs:\n",
        "    norma =np.sqrt(sum(e**2))\n",
        "    if norma < 0.99 or norma > 1.01:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "if not(is_normalized(embeddings)):\n",
        "  print(\"\\nAviso! Los vectores no estan normalizados en la salida de este modelo. Se recomienda marcar la casilla 'NORMALIZE_EMBEDDINGS' para que\\nlas similitudes se encuentren en un rango entre 0 y 1 , para así poder interpretarlas de manera más sencilla.\")\n",
        "\n",
        "if SAVE_EMBEDDINGS:\n",
        "  print('Guardando embeddings...')\n",
        "  with open(saved_embeddings_dir + OUTPUT_NAME_EMBEDDINGS +'.pkl', \"wb\") as fOut:\n",
        "    pickle.dump(embeddings, fOut, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3KgW2qEwq-q"
      },
      "outputs": [],
      "source": [
        "#@title Cargar embeddings. { display-mode: \"form\" }\n",
        "\n",
        "EMBEDDINGS_FILE_NAME = \"embeddings-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  with open(saved_embeddings_dir + EMBEDDINGS_FILE_NAME +'.pkl', \"rb\") as fIn:\n",
        "      embeddings = pickle.load(fIn)\n",
        "except Exception as e:\n",
        "  raise\n",
        "else:\n",
        "  print(\"Embeddings cargados correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_rbgn4CSGmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72tQ2538zE19"
      },
      "outputs": [],
      "source": [
        "#@title Explorar embeddings en el espacio. { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "# embeddings = embeddings_aux.cpu()\n",
        "\n",
        "n_neighbors= 25#valores pequeños mantienen mas informacion local,  valores grandes mas informacion global\n",
        "umap_embeddings = umap.UMAP(n_neighbors=n_neighbors, \n",
        "                            n_components=10, \n",
        "                            metric='cosine').fit_transform(embeddings)\n",
        "clusters = hdbscan.HDBSCAN(min_cluster_size=3,\n",
        "                          metric='euclidean',                      \n",
        "                          cluster_selection_method='eom').fit(umap_embeddings)\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(umap_embeddings) \n",
        "X_pca = pca.transform(umap_embeddings) \n",
        "\n",
        "Xax = X_pca[:,0]\n",
        "Yax = X_pca[:,1]\n",
        "Zax = X_pca[:,2]\n",
        "\n",
        "try:\n",
        "  fig = px.scatter_3d(df,\n",
        "                      x=Xax,\n",
        "                      y=Yax,\n",
        "                      z=Zax,\n",
        "                      hover_data =[TITLE_COLUMN],\n",
        "                      hover_name = df.index,\n",
        "                      height=1000,\n",
        "                      opacity=0.7,\n",
        "                      color = clusters.labels_)\n",
        "except:\n",
        "  print(\"Columna TITLE_COLUMN no encontrada, solo mostrando index el en cada punto\")\n",
        "  try:\n",
        "    fig = px.scatter_3d(df,\n",
        "                        x=Xax,\n",
        "                        y=Yax,\n",
        "                        z=Zax,\n",
        "                        hover_name = df.index,\n",
        "                        height=1000,\n",
        "                        opacity=0.7,\n",
        "                        color = clusters.labels_)\n",
        "  except:\n",
        "    raise\n",
        "  \n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uisvT2lzS7kl"
      },
      "source": [
        "#Exploración en tiempo real.\n",
        "\n",
        "En esta sección se puede explorar el conjunto de datos en tiempo real sin necesidad de tener calculada la matriz de similitud. Es necesario haber ejecutado la creación o el cargado de los sentence embeddings antes de ejecutar a la exploración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWppGQDcT2Ma"
      },
      "outputs": [],
      "source": [
        "#@title Explorar uno con todos. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown *   **INDEX_IN_CSV** : Indica el index del elemento del que se desea obtener sus similares.\n",
        "\n",
        "#@markdown *   **NUM_SAVE** : Número de elementos similares que se desea obtener.\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "INDEX_IN_CSV = 55 #@param {type:\"integer\"}\n",
        "NUM_SAVE =  20#@param {type:\"integer\"}\n",
        "\n",
        "#Configuramos faiss\n",
        "if torch.cuda.is_available():\n",
        "  cfg = faiss.GpuIndexFlatConfig()\n",
        "  cfg.useFloat16 = True\n",
        "  index = faiss.GpuIndexFlatIP(faiss.StandardGpuResources(), embeddings.shape[1], cfg)\n",
        "else:\n",
        "  index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "\n",
        "index.add(embeddings)\n",
        "\n",
        "if NUM_SAVE < 0:\n",
        "  NUM_SAVE = 0\n",
        "if NUM_SAVE >= len(df):\n",
        "  NUM_SAVE = len(df)  - 1\n",
        "  \n",
        "cosenos, indices = index.search(np.array([embeddings[INDEX_IN_CSV]]), NUM_SAVE + 1)\n",
        "cosenos = cosenos[0]\n",
        "indices = indices[0]\n",
        "\n",
        "\n",
        "print(\"Texto a explorar:\\n\")\n",
        "print(textwrap.fill(df[EMBD_COLUMN][INDEX_IN_CSV][0:465], 70))\n",
        "\n",
        "if TITLE_COLUMN == \"\":\n",
        "  df_similares = pd.DataFrame(df.iloc[indices[1:]], columns = {EMBD_COLUMN, 'similarity'})\n",
        "  df_similares = df_similares[['similarity', EMBD_COLUMN]]\n",
        "else:\n",
        "  df_similares = pd.DataFrame(df.iloc[indices[1:]], columns = {TITLE_COLUMN, EMBD_COLUMN, 'similarity'})\n",
        "  df_similares = df_similares[['similarity', TITLE_COLUMN, EMBD_COLUMN]]\n",
        "\n",
        "df_similares['similarity'] = cosenos[1:]\n",
        "\n",
        "data_table.DataTable(df_similares, include_index=False, num_rows_per_page=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyapINAGXFOu"
      },
      "outputs": [],
      "source": [
        "#@title Explorar todos con tu propio texto. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown *   **TEXT** : Texto con el que se desea comparar los elementos del conjunto de datos.\n",
        "\n",
        "#@markdown *   **NUM_SAVE** : Número de elementos similares que se desean obtener.\n",
        "\n",
        "#@markdown\n",
        "\n",
        "TEXT =  \"deep neural network for games\" #@param {type:\"string\"}\n",
        "NUM_SAVE =  15#@param {type:\"integer\"}\n",
        "\n",
        "query_embedding = BIENCODER_MODEL.encode([TEXT],\n",
        "                                    convert_to_tensor=False,\n",
        "                                    device = str(device),\n",
        "                                    show_progress_bar=True,\n",
        "                                    normalize_embeddings= True)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#Configuramos faiss\n",
        "if torch.cuda.is_available():\n",
        "  cfg = faiss.GpuIndexFlatConfig()\n",
        "  cfg.useFloat16 = True\n",
        "  index = faiss.GpuIndexFlatIP(faiss.StandardGpuResources(), embeddings.shape[1], cfg)\n",
        "else:\n",
        "  index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "\n",
        "index.add(embeddings)\n",
        "\n",
        "if NUM_SAVE <= 0:\n",
        "  NUM_SAVE = 1\n",
        "if NUM_SAVE > len(df):\n",
        "  NUM_SAVE = len(df)\n",
        "  \n",
        "cosenos, indices = index.search(np.array(query_embedding), NUM_SAVE)\n",
        "cosenos = cosenos[0]\n",
        "indices = indices[0]\n",
        "\n",
        "print(\"Texto a explorar:\\n\")\n",
        "print(textwrap.fill(TEXT, 230))\n",
        "\n",
        "if TITLE_COLUMN == \"\":\n",
        "  df_similares = pd.DataFrame(df.iloc[indices],columns = {EMBD_COLUMN, 'similarity'})\n",
        "  df_similares = df_similares[['similarity', EMBD_COLUMN]]\n",
        "else:\n",
        "  df_similares = pd.DataFrame(df.iloc[indices],columns = {TITLE_COLUMN, EMBD_COLUMN, 'similarity'})\n",
        "  df_similares = df_similares[['similarity', TITLE_COLUMN, EMBD_COLUMN]]\n",
        "\n",
        "\n",
        "df_similares['similarity'] = cosenos\n",
        "\n",
        "data_table.DataTable(df_similares, include_index=False, num_rows_per_page=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXk2ll9Q0yX7"
      },
      "source": [
        "#Cálculo o carga de similitudes: Faiss.\n",
        "\n",
        "En esta sección se calcula o carga la matriz de similitudes entre los sentence embeddings utilizando Faiss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4iCyDgDZf7W"
      },
      "outputs": [],
      "source": [
        "#@title Cálculo de similitudes - Bi-encoder { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Esta celda permite calcular la matriz de similitudes. Para ello se deben de indicar los siguientes parámetros:\n",
        "\n",
        "#@markdown *   **NUM_SAVE**: Número de elementos similares que se quieren guardar para cada uno de los elementos del conjunto de datos.\n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_PICKLE**: Si la casilla está marcada la matriz de similitudes será guardada en formato .pkl con el nombre indicado en OUTPUT_NAME. Si se quieren cargar posteriormente en este cuaderno se deben de guardar con este formato. \n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_CSV**: Si la casilla está marcada la matriz de similitudes será guardada en formato .csv con el nombre indicado en OUTPUT_NAME. Usar cuando se quiera exportar los datos a otra plataforma en la que utilizar el archivo en formato csv.\n",
        "\n",
        "#@markdown *   **OUTPUT_NAME**: Nombre del fichero en el que se guardará la matriz de similitudes generada.\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "NUM_SAVE = 987632469 #@param {type:\"integer\"}\n",
        "SAVE_SIMILARITY_MATRIX_PICKLE = False #@param {type:\"boolean\"}\n",
        "SAVE_SIMILARITY_MATRIX_CSV = False #@param {type:\"boolean\"}\n",
        "OUTPUT_NAME = \"similarity_matrix-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "def fun_cosenos_biencoder(NUM_SAVE: int):\n",
        " #Configuramos faiss\n",
        "  if torch.cuda.is_available():\n",
        "    cfg = faiss.GpuIndexFlatConfig()\n",
        "    cfg.useFloat16 = True\n",
        "    index = faiss.GpuIndexFlatIP(faiss.StandardGpuResources(), embeddings.shape[1], cfg)\n",
        "  else:\n",
        "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "    \n",
        "  index.add(embeddings)\n",
        "\n",
        "  D, I = index.search(embeddings, NUM_SAVE + 1)\n",
        "  return [lista[1:] for lista in D], [lista[1:] for lista in I]\n",
        "\n",
        "\n",
        "if NUM_SAVE > len(df):\n",
        "  NUM_SAVE = len(df) - 1\n",
        "if NUM_SAVE > 2047:\n",
        "  NUM_SAVE = 2047\n",
        "\n",
        "cosenos_biencoder, index_biencoder = fun_cosenos_biencoder(NUM_SAVE)\n",
        "df['index_biencoder'] = index_biencoder\n",
        "df['cosenos_biencoder'] = cosenos_biencoder\n",
        "\n",
        "#Al guardar listas como csv y luego leerlas se convierten a string, por lo que se dejan los valores separados por\n",
        "#comas para poder parsearlo de manera más sencilla al leerlo\n",
        "df['index_biencoder'] = df['index_biencoder'].map(lambda x: ','.join(map(str, x)))\n",
        "df['cosenos_biencoder'] = df['cosenos_biencoder'].map(lambda x: ','.join(map(str, x)))\n",
        "\n",
        "if SAVE_SIMILARITY_MATRIX_CSV:\n",
        "  print(\"Guardando {}.csv...\".format(OUTPUT_NAME))\n",
        "  df.to_csv(similarity_matrix_dir + OUTPUT_NAME +'.csv',columns={'cosenos_biencoder','index_biencoder'},index=False)\n",
        "if SAVE_SIMILARITY_MATRIX_PICKLE:\n",
        "  print(\"Guardando {}.pkl...\".format(OUTPUT_NAME))\n",
        "  with open(similarity_matrix_dir + OUTPUT_NAME +'.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'cosenos_biencoder': cosenos_biencoder, 'index_biencoder': index_biencoder}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Mostrando los primeros elementos...\")\n",
        "data_table.DataTable(df[['index_biencoder','cosenos_biencoder']].head(), include_index=True, num_rows_per_page=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk76gj7XFr7A"
      },
      "outputs": [],
      "source": [
        "#@title Cargar matriz de similitudes - Bi-encoder. { display-mode: \"form\" }\n",
        "#@markdown Si se tiene la matriz de similitud ya calculada,se puede cargar el fichero con la misma y evitar tener que calcularla de nuevo. Indicar el nombre del fichero (en formato .pkl):\n",
        "\n",
        "MATRIX_FILE_NAME = \"similarity_matrix-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  with open(similarity_matrix_dir + MATRIX_FILE_NAME +'.pkl', \"rb\") as fIn:\n",
        "      resp = pickle.load(fIn)\n",
        "      cosenos_biencoder = resp['cosenos_biencoder']\n",
        "      index_biencoder = resp['index_biencoder']\n",
        "      df['index_biencoder'] = index_biencoder\n",
        "      df['cosenos_biencoder'] = cosenos_biencoder\n",
        "except Exception as e:\n",
        "  raise e\n",
        "else:\n",
        "  print(\"Matriz de similitudes cargada correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHIBy3-wjCm4"
      },
      "source": [
        "#Re-ranking o carga de las similitudes: Cross-Encoder.\n",
        "\n",
        "En esta sección se calcula o carga la matriz de similitudes entre los sentence embeddings utilizando el Cross-encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JectAJp_lG1Z"
      },
      "outputs": [],
      "source": [
        "#@title Re-ranking de resultados : Cross-encoder. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown En esta sección se obtendrá un nuevo orden (re-reranking) para los resultados obtenidos con el Bi-encoder. Este tipo de modelo es mucho más lento pero más preciso, por lo que se recomienda que el número de elementos similares que se desean re-ordenar de cada elemento del conjunto de datos no sea muy grande. <b>(No se recomienda ejecutar sin disponer de una GPU)\n",
        "\n",
        "#@markdown En la esta celda se inicializa el modelo Cross-encoder a utilizar.\n",
        "\n",
        "#@markdown Se deben rellenar los siguientes parámetros:\n",
        "\n",
        "#@markdown *   **MODEL_NAME_CROSSENCODER**: Nombre del modelo Cross-encoder que se va a utilizar.\n",
        "\n",
        "#@markdown *   **NUM_SAVE**: Número de elementos similares a cada elemento obtenidos por el Bi-encoder que se desean re-rankear.\n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_PICKLE**: Si la casilla está marcada la matriz de similitudes será guardada en formato .pkl con el nombre indicado en OUTPUT_NAME. Si se quieren cargar posteriormente en este cuaderno se deben de guardar con este formato. \n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_CSV**: Si la casilla está marcada la matriz de similitudes será guardada en formato .csv con el nombre indicado en OUTPUT_NAME. Usar cuando se quiera exportar los datos a otra plataforma en la que utilizar el archivo en formato csv.\n",
        "\n",
        "#@markdown *   **OUTPUT_NAME**: Nombre del fichero en el que se guardará la matriz de similitudes generada.\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "MODEL_NAME_BIENCODER = 'cross-encoder/ms-marco-MiniLM-L-12-v2' #@param {type:\"string\"}\n",
        "NUM_SAVE =  10#@param {type:\"integer\"}\n",
        "SAVE_SIMILARITY_MATRIX_PICKLE = True #@param {type:\"boolean\"}\n",
        "SAVE_SIMILARITY_MATRIX_CSV = False #@param {type:\"boolean\"}\n",
        "OUTPUT_NAME = \"similarity_matrix-crossencoder-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "model_cross_encoder = CrossEncoder(MODEL_NAME_BIENCODER, num_labels = 1)\n",
        "\n",
        "def fun_cosenos_1_crossencoder(elemento: int, listaElementos):\n",
        "  query = str(listaElementos[elemento]) #LOS NAN DAN ERROR. Añadimos str para evitarlo y funciona.\n",
        "  # With all sentences in the corpus\n",
        "  corpus = [str(listaElementos[ind]) for ind in index_biencoder[elemento][0:NUM_SAVE]]\n",
        "\n",
        "  # So we create the respective sentence combinations\n",
        "  sentence_combinations = [[query, corpus_sentence] for corpus_sentence in corpus]\n",
        "\n",
        "  # Compute the similarity scores for these combinations\n",
        "  cosenos_1_crossencoder = model_cross_encoder.predict(sentence_combinations, show_progress_bar = False, convert_to_tensor=True)\n",
        "  D, I = torch.topk(cosenos_1_crossencoder, k = len(cosenos_1_crossencoder))\n",
        "\n",
        "  return D.tolist(), I.tolist()\n",
        "\n",
        "def fun_cosenos_crossencoder(elemento_ini: int, elemento_fin: int, listaElementos):\n",
        "\n",
        "  cosenos_crossencoder = []\n",
        "  index_crossencoder = []\n",
        "  for i in range(elemento_ini, elemento_fin):\n",
        "    out.update(progress(i, elemento_fin))\n",
        "    resultado = fun_cosenos_1_crossencoder(i, listaElementos)\n",
        "    cosenos_crossencoder.append(resultado[0])\n",
        "    index_crossencoder.append([index_biencoder[i][x] for x in resultado[1]])\n",
        "\n",
        "  return cosenos_crossencoder, index_crossencoder\n",
        "\n",
        "if len(index_biencoder) > 0 and NUM_SAVE > len(index_biencoder[0]):\n",
        "  NUM_SAVE = len(index_biencoder[0])\n",
        "\n",
        "if NUM_SAVE <= 0:\n",
        "  raise Exception('NUM_SAVE debe ser mayor que 0 y menor o igual al NUM_SAVE utilizado en el Biencoder.')\n",
        "\n",
        "out = display(progress(0, len(df)), display_id=True)\n",
        "\n",
        "cosenos_crossencoder, index_crossencoder = fun_cosenos_crossencoder(0, len(df), df[EMBD_COLUMN].tolist())\n",
        "df['index_crossencoder'] = index_crossencoder\n",
        "df['cosenos_crossencoder'] = cosenos_crossencoder\n",
        "\n",
        "if SAVE_SIMILARITY_MATRIX_CSV:\n",
        "  print(\"Guardando {}.csv...\".format(OUTPUT_NAME))\n",
        "  df.to_csv(similarity_matrix_dir + OUTPUT_NAME +'.csv',columns={'cosenos_crossencoder','index_crossencoder'},index=False)\n",
        "if SAVE_SIMILARITY_MATRIX_PICKLE:\n",
        "  print(\"Guardando {}.pkl...\".format(OUTPUT_NAME))\n",
        "  with open(similarity_matrix_dir + OUTPUT_NAME +'.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'cosenos_crossencoder': cosenos_crossencoder, 'index_crossencoder': index_crossencoder}, fOut, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyILZ1bAJ3OP"
      },
      "outputs": [],
      "source": [
        "#@title Cargar matriz de similitudes : Cross-encoder. { display-mode: \"form\" }\n",
        "#@markdown Si se tiene la matriz de similitud ya calculada,se puede cargar el fichero con la misma y evitar tener que calcularla de nuevo. Indicar el nombre del fichero (en formato .pkl):\n",
        "\n",
        "MATRIX_FILE_NAME = \"similarity_matrix-crossencoder-abstracts-arxiv\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "  with open(similarity_matrix_dir + MATRIX_FILE_NAME +'.pkl', \"rb\") as fIn:\n",
        "      resp = pickle.load(fIn)\n",
        "      cosenos_crossencoder = resp['cosenos_crossencoder']\n",
        "      index_crossencoder = resp['index_crossencoder']\n",
        "      df['index_crossencoder'] = index_crossencoder\n",
        "      df['cosenos_crossencoder'] = cosenos_crossencoder\n",
        "except Exception as e:\n",
        "  print(\"Hay algún problema con el fichero indicado.\")\n",
        "  raise\n",
        "else:\n",
        "  print(\"Matriz de similitudes cargada correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtIl5pWu-Q9A"
      },
      "source": [
        "#Exploración de la matriz de similitud.\n",
        "\n",
        "En esta sección se pueden explorar los resultados obtenidos anteriormente con el Bi-encoder o el Cross-encoder. Es necesario haber ejecutado al menos el calculo de las similitudes con el Bi-encoder antes de lanzarte a la exploración.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXPSLVC2-X2m"
      },
      "outputs": [],
      "source": [
        "#@title Obtener similares a un elemento dado. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown *   BI_CO: Indica el encoder sobre el que quieres explorar los resultados.\n",
        "\n",
        "#@markdown *   INDEX_IN_CSV: Indica el índice del elemento del que deseas explorar las similares.\n",
        "\n",
        "BI_CO = \"Bi-encoder\" #@param ['Bi-encoder', 'Cross-encoder'] {allow-input: false}\n",
        "INDEX_IN_CSV =  0#@param {type:\"integer\"}\n",
        "\n",
        "print(\"Texto a explorar:\\n\")\n",
        "print(textwrap.fill(df[EMBD_COLUMN][INDEX_IN_CSV], 230))\n",
        "\n",
        "if BI_CO == 'Bi-encoder':\n",
        "  indexes_aux = index_biencoder\n",
        "  cosenos_aux = cosenos_biencoder\n",
        "elif BI_CO == 'Cross-encoder':\n",
        "  indexes_aux = index_crossencoder\n",
        "  cosenos_aux = cosenos_crossencoder\n",
        "else:\n",
        "  raise Exception(\"El encoder proporcionado no es valido\")\n",
        "\n",
        "df_similares = pd.DataFrame(df.iloc[indexes_aux[INDEX_IN_CSV]], columns = {EMBD_COLUMN, 'similarity'})\n",
        "df_similares['similarity'] = cosenos_aux[INDEX_IN_CSV]\n",
        "\n",
        "data_table.DataTable(df_similares, include_index=True, num_rows_per_page=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhkVrcYrzSyL"
      },
      "source": [
        "#Exportar dataframe a una base de datos\n",
        "Se exporta el conjunto de datos cargados junto a las columnas que contienen los indices y similitudes de las más parecidas a cada elemento a una base de datos MYSQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq-cYHVV4ILC"
      },
      "outputs": [],
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "#@markdown *   **MYSQL_HOST**: Dirección del host de la DB. (Ejemplo: 82.54.219.71:3306 o localhost)\n",
        "\n",
        "#@markdown *   **MYSQL_USER**: Usuario de la DB (Ejemplo: root).\n",
        "\n",
        "#@markdown *   **MYSQL_PASSWORD**: Contraseña del usuario de la DB. \n",
        "\n",
        "#@markdown *   **MYSQL_DB**: Nombre del schema de la DB.\n",
        "\n",
        "#@markdown *   **MYSQL_TABLE_NAME**: Nombre de la tabla a la que se desea exportar los datos.\n",
        "\n",
        "MYSQL_HOST = \"localhost\" #@param {type:\"string\"}\n",
        "MYSQL_USER = \"root\" #@param {type:\"string\"}\n",
        "MYSQL_PASSWORD = \"localhost\" #@param {type:\"string\"}\n",
        "MYSQL_DB = \"bd_tfg\" #@param {type:\"string\"}\n",
        "MYSQL_TABLE_NAME = \"tfg\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "engine = create_engine(\"mysql+pymysql://\" + MYSQL_USER + \":\" + MYSQL_PASSWORD + \"@\" + MYSQL_HOST + \"/\" + MYSQL_DB)\n",
        "df.to_sql(MYSQL_TABLE_NAME, con=engine, if_exists='replace', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msoFJ7KHnxfe"
      },
      "source": [
        "# Exploración con otro conjunto de datos.\n",
        "En esta sección se puede explorar el conjunto de datos cargado con el que se le indica por parámetos. Es necesario haber ejecutado la inicialización del modelo y la creación o el cargado de embeddings del conjunto original antes de ejecutar a la exploración con el nuevo conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UbjgNca7JCC"
      },
      "outputs": [],
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Se deben indicar los siguientes parámetros:\n",
        "\n",
        "#@markdown *   **DF_NAME**: Nombre del conjunto de datos con el que se desea comparar el actual. Debe estar en la carpeta WS_PATH y debe de ser un fichero de  formato csv. **(Ejemplo: booksummaries.csv)**.\n",
        "\n",
        "#@markdown *   **EMBD_COLUMN_COMPARE**: Nombre de la columna del conjunto de datos que contiene los textos que se compararan con el conjunto actual.\n",
        "\n",
        "#@markdown *   **NUM_SAVE** : Número de elementos similares que se desea obtener.\n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_PICKLE**: Si la casilla está marcada la matriz de similitudes será guardada en formato .pkl con el nombre indicado en OUTPUT_NAME. Si se quieren cargar posteriormente en este cuaderno se deben de guardar con este formato. \n",
        "\n",
        "#@markdown *   **SAVE_SIMILARITY_MATRIX_CSV**: Si la casilla está marcada la matriz de similitudes será guardada en formato .csv con el nombre indicado en OUTPUT_NAME. Usar cuando se quiera exportar los datos a otra plataforma en la que utilizar el archivo en formato csv.\n",
        "\n",
        "#@markdown *   **OUTPUT_NAME** :  Nombre con el que serán guardada la matriz de similitudes. **(Ejemplo: similitudes_elementos)**\n",
        "\n",
        "\n",
        "\n",
        "#@markdown <br>\n",
        "DF_NAME=  \"arxiv_data.csv\" #@param {type:\"string\"}\n",
        "EMBD_COLUMN_COMPARE=  \"titles\" #@param {type:\"string\"}\n",
        "NUM_SAVE = 25 #@param {type:\"integer\"}\n",
        "SAVE_SIMILARITY_MATRIX_PICKLE = True #@param {type:\"boolean\"}\n",
        "SAVE_SIMILARITY_MATRIX_CSV = False #@param {type:\"boolean\"}\n",
        "OUTPUT_NAME =\"similarity with arxiv titles\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "df_compare = pd.read_csv(WS_PATH + DF_NAME)\n",
        "if EMBD_COLUMN_COMPARE not in df_compare.columns:\n",
        "  print(\"Columnas cargadas: \", list(df_compare.columns))\n",
        "  raise Exception(\"La columna {} no se encuentra en el conjunto de datos cargado.\".format(EMBD_COLUMN_COMPARE))\n",
        "\n",
        "df_compare[EMBD_COLUMN_COMPARE] = df_compare[EMBD_COLUMN_COMPARE].astype(\"string\")\n",
        "print(\"Número de elementos cargados: \", len(df_compare), '\\n')\n",
        "\n",
        "print('Usando el modelo:\\n')\n",
        "print(BIENCODER_MODEL)\n",
        "\n",
        "print('\\nComputing query embeddings...')\n",
        "query_embeddings = BIENCODER_MODEL.encode(df_compare[EMBD_COLUMN_COMPARE],\n",
        "                                    convert_to_tensor=False,\n",
        "                                    device = str(device),\n",
        "                                    batch_size = 32,\n",
        "                                    show_progress_bar=True,\n",
        "                                    normalize_embeddings= True)\n",
        "\n",
        "\n",
        "def fun_cosenos_df_compare(NUM_SAVE: int):\n",
        " #Configuramos faiss\n",
        "  if torch.cuda.is_available():\n",
        "    cfg = faiss.GpuIndexFlatConfig()\n",
        "    cfg.useFloat16 = True\n",
        "    index = faiss.GpuIndexFlatIP(faiss.StandardGpuResources(), embeddings.shape[1], cfg)\n",
        "  else:\n",
        "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "    \n",
        "  index.add(embeddings)\n",
        "\n",
        "  D, I = index.search(query_embeddings, NUM_SAVE)\n",
        "  return list(D), list(I)\n",
        "\n",
        "if NUM_SAVE >= len(df):\n",
        "  NUM_SAVE = len(df)  - 1\n",
        "if NUM_SAVE > 2048:\n",
        "  NUM_SAVE = 2048\n",
        "\n",
        "cosenos_df_compare, index_df_compare = fun_cosenos_df_compare(NUM_SAVE)\n",
        "df_res_compare = pd.DataFrame()\n",
        "df_res_compare['index_compare'] = index_df_compare\n",
        "df_res_compare['cosenos_compare'] = cosenos_df_compare\n",
        "\n",
        "if SAVE_SIMILARITY_MATRIX_CSV:\n",
        "  print(\"Guardando {}.csv...\".format(OUTPUT_NAME))\n",
        "  df_res_compare.to_csv(similarity_matrix_dir + OUTPUT_NAME + \".csv\",index=False)\n",
        "if SAVE_SIMILARITY_MATRIX_PICKLE:\n",
        "  print(\"Guardando {}.pkl...\".format(OUTPUT_NAME))\n",
        "  df_res_compare.to_pickle(similarity_matrix_dir + OUTPUT_NAME + \".pkl\",protocol = pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Mostando primeros elementos...\\n\")\n",
        "data_table.DataTable(df_res_compare.head(10), include_index=True, num_rows_per_page=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uisvT2lzS7kl"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}